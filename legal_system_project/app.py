import gradio as gr
import os
import json
import pandas as pd
from datetime import datetime
import time
from typing import List
import re
import uuid
import hashlib

from services import (
    ContractAnalyzer,
    CaseAnalysisGenerator,
    ParalegalAssistant,
    LawyerPromptLoader,
)
from utils import (
    classify_contract_type,
    extract_text_from_file,
)
import config
import prompts
from dashscope import Generation
from dashscope.api_entities.dashscope_response import Role

# System State
class SystemState:
    def __init__(self):
        self.current_mode = "selection"  # selection, legal_knowledge, case_strategy, contract_review
        self.legal_conversation_history = []
        self.case_conversation_history = []
        self.contract_review_history = []
        self.user_input_round = 0
        self.case_type_selected = None
        self.current_lawyer_prompt = None
        # æ–°å¢ï¼šç”¨äºå¤„ç†continue_promptçš„çŠ¶æ€
        self.expecting_continue_response = False
        self.loaded_history_for_prompt = None
        self.loaded_state_for_prompt = None

# Global dictionary to store user states by UUID
user_states = {}

def get_user_id_from_request(request: gr.Request):
    """Generate a stable user ID using request headers (browser + IP)."""
    try:
        # print(request)
        user_agent = request.headers.get('user-agent', '') if hasattr(request, 'headers') else ''
        forwarded_for = request.headers.get('x-forwarded-for', '') if hasattr(request, 'headers') else ''
        real_ip = request.headers.get('x-real-ip', '') if hasattr(request, 'headers') else ''
        # remote_addr = getattr(request, 'client', {}).get('host', '') if hasattr(request, 'client') else ''
        identifier = f"{user_agent}:{forwarded_for}:{real_ip}"
        # print(identifier)
        user_hash = hashlib.md5(identifier.encode()).hexdigest()[:16]
        return f"user_{user_hash}"
    except Exception:
        print("Error in get_user_id_from_request")
        return f"user_{str(uuid.uuid4())[:12]}"

def get_or_create_user_state(request: gr.Request, user_id=None):
    """Get or create user state for a given user ID."""
    if user_id is None:
        user_id = get_user_id_from_request(request)
    if user_id not in user_states:
        user_states[user_id] = SystemState()
    return user_id, user_states[user_id]

# For backward compatibility, create a default system state
system_state = SystemState()

# Instantiate services
contract_analyzer = ContractAnalyzer()
case_analyzer = CaseAnalysisGenerator()
paralegal = ParalegalAssistant()
prompt_loader = LawyerPromptLoader()

# Helper functions
def get_formatted_time():
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def save_conversation(history, mode):
    if not os.path.exists("conversation_datasets"):
        os.makedirs("conversation_datasets")
    
    filename = f"conversation_datasets/{mode}_conversation_{get_formatted_time()}.json"
    
    formatted_conversation = {
        "conversation_id": f"{mode}_{get_formatted_time()}",
        "model_a": config.LAWYER_MODEL if mode == 'case' else config.LEGAL_MODEL,
        "conversations": []
    }
    
    for user_msg, bot_msg in history:
        formatted_conversation["conversations"].append({"from": "human", "value": user_msg})
        formatted_conversation["conversations"].append({"from": "gpt", "value": bot_msg})
        
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump([formatted_conversation], f, ensure_ascii=False, indent=4)
    
    return filename

def save_analysis_result(result_text):
    if not os.path.exists("case_analysis_results"):
        os.makedirs("case_analysis_results")
    
    filename = f"case_analysis_results/case_analysis_{get_formatted_time()}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(result_text)
    return filename

def get_user_chat_file_path(user_id):
    """Get the file path for storing user's chat history."""
    if not os.path.exists("user_histories"):
        os.makedirs("user_histories")
    return f"user_histories/{user_id}_chat_history.json"

def save_user_chat_history(user_id, history, user_state):
    """Save user's chat history and state to a JSON file."""
    try:
        chat_data = {
            "user_id": user_id,
            "last_updated": datetime.now().isoformat(),
            "chat_history": history,
            "user_state": {
                "current_mode": user_state.current_mode,
                "user_input_round": user_state.user_input_round,
                "case_type_selected": user_state.case_type_selected,
                "current_lawyer_prompt": user_state.current_lawyer_prompt,
                "legal_conversation_history": user_state.legal_conversation_history,
                "case_conversation_history": user_state.case_conversation_history,
                "contract_review_history": user_state.contract_review_history
            }
        }
        
        file_path = get_user_chat_file_path(user_id)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(chat_data, f, ensure_ascii=False, indent=2)
        
        return file_path
    except Exception as e:
        print(f"ä¿å­˜ç”¨æˆ·èŠå¤©è®°å½•å¤±è´¥: {e}")
        return None

def load_user_chat_history(user_id):
    """Load user's chat history and state from JSON file."""
    try:
        file_path = get_user_chat_file_path(user_id)
        if not os.path.exists(file_path):
            return None, None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            chat_data = json.load(f)
        
        # Load chat history
        history = chat_data.get("chat_history", [])
        
        # Restore user state
        state_data = chat_data.get("user_state", {})
        user_state = SystemState()
        user_state.current_mode = state_data.get("current_mode", "selection")
        user_state.user_input_round = state_data.get("user_input_round", 0)
        user_state.case_type_selected = state_data.get("case_type_selected", None)
        user_state.current_lawyer_prompt = state_data.get("current_lawyer_prompt", None)
        user_state.legal_conversation_history = state_data.get("legal_conversation_history", [])
        user_state.case_conversation_history = state_data.get("case_conversation_history", [])
        user_state.contract_review_history = state_data.get("contract_review_history", [])
        
        return history, user_state
    except Exception as e:
        print(f"åŠ è½½ç”¨æˆ·èŠå¤©è®°å½•å¤±è´¥: {e}")
        return None, None

def get_initial_prompt():
    return '''
ğŸ›ï¸ **æ¬¢è¿ä½¿ç”¨AIæ³•å¾‹åŠ©æ‰‹ï¼**

æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ä¸‰ç§ä¸“ä¸šçš„æ³•å¾‹æœåŠ¡ï¼š

ğŸ“„ **åˆåŒå®¡æŸ¥** - ä¸Šä¼ åŠ³åŠ¨åˆåŒæ–‡ä»¶ï¼Œä¸ºæ‚¨åˆ†æåˆåŒåˆè§„æ€§ï¼š
   â€¢ è‡ªåŠ¨è¯†åˆ«åˆåŒç±»å‹  â€¢ æ£€æµ‹æ½œåœ¨é£é™©å’Œæ¼æ´  â€¢ æä¾›ä¸“ä¸šçš„æ³•å¾‹å»ºè®®

ğŸ“š **æ³•å¾‹çŸ¥è¯†å’¨è¯¢** - ä¸ºæ‚¨è§£ç­”å„ç±»æ³•å¾‹çŸ¥è¯†é—®é¢˜ï¼š
   â€¢ åˆåŒæ³•ã€æ°‘æ³•ã€åˆ‘æ³•ç­‰æ³•å¾‹æ¡æ–‡è§£é‡Š  
   â€¢ å©šå§»å®¶åº­æ³•ã€æˆ¿åœ°äº§æ³•ã€çŸ¥è¯†äº§æƒæ³•ç­‰ä¸“ä¸šé¢†åŸŸ
   â€¢ æ¶ˆè´¹è€…æƒç›Šã€å…¬å¸æ³•ç­‰å®ç”¨æ³•å¾‹çŸ¥è¯†

âš–ï¸ **æ¡ˆä»¶ç­–ç•¥å’¨è¯¢** - é’ˆå¯¹æ‚¨çš„å…·ä½“æ¡ˆä»¶æä¾›ä¸“ä¸šåˆ†æï¼š
   â€¢ åŠ³åŠ¨äº‰è®®æ¡ˆä»¶åˆ†æä¸ç­–ç•¥åˆ¶å®š  â€¢ å…·ä½“æ¡ˆæƒ…çš„æ³•å¾‹é£é™©è¯„ä¼°  â€¢ ç»´æƒè·¯å¾„å’Œèµ”å¿æ–¹æ¡ˆå»ºè®®

**è¯·ç›´æ¥å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆæœåŠ¡ï¼Œæˆ–æè¿°æ‚¨çš„é—®é¢˜ï¼š**

ğŸ’¡ æ‚¨å¯ä»¥è¯´ï¼š"å¸®æˆ‘å®¡æŸ¥ä¸€ä¸‹åŠ³åŠ¨åˆåŒ"ï¼ˆåˆåŒå®¡æŸ¥ï¼‰
ğŸ’¡ æˆ–è€…è¯´ï¼š"æˆ‘æƒ³äº†è§£åŠ³åŠ¨æ³•çš„ç›¸å…³æ³•å¾‹è§„å®š"ï¼ˆæ³•å¾‹çŸ¥è¯†å’¨è¯¢ï¼‰
ğŸ’¡ æˆ–è€…è¯´ï¼š"å…¬å¸çªç„¶è¾é€€äº†æˆ‘ï¼Œæˆ‘è¯¥æ€ä¹ˆåŠï¼Ÿ"ï¼ˆæ¡ˆä»¶ç­–ç•¥å’¨è¯¢ï¼‰

**æˆ–ç›´æ¥ä¸Šä¼ åˆåŒæ–‡ä»¶å¼€å§‹åˆåŒå®¡æŸ¥ï¼**
'''

def analyze_contracts(files):
    if not files:
        yield "âŒ **é”™è¯¯**ï¼šè¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚"
        return

    file_paths = [f.name for f in files]

    if len(file_paths) > 1:
        if all(p.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')) for p in file_paths):
            mode = "multi_image"
        else:
            yield "âŒ **é”™è¯¯**ï¼šä¸Šä¼ å¤šä¸ªæ–‡ä»¶æ—¶ï¼Œå¿…é¡»å…¨éƒ¨æ˜¯å›¾ç‰‡ã€‚"
            return
    elif file_paths[0].lower().endswith(('.pdf', '.docx', '.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')):
        mode = "single_document"
    else:
        yield "âŒ **é”™è¯¯**ï¼šä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚è¯·ä¸Šä¼  PDF, DOCX, æˆ–å›¾ç‰‡æ–‡ä»¶ã€‚"
        return

    try:
        yield "â³ **æ­£åœ¨æå–æ–‡æœ¬...**"
        if mode == "multi_image":
            text = contract_analyzer.extract_texts_from_multiple_images(file_paths)
        else:
            text = extract_text_from_file(file_paths[0])

        if not text.strip():
            yield "âŒ **é”™è¯¯**ï¼šæœªèƒ½ä»æ–‡ä»¶ä¸­æå–åˆ°ä»»ä½•æ–‡æœ¬ã€‚"
            return

        contract_type = classify_contract_type(text)
        yield f"ğŸ“Œ **åˆæ­¥è¯†åˆ«çš„åˆåŒç±»å‹**ï¼š{contract_type}\n\n---\n\nâ³ **æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¯·ç¨å€™...**"

        full_response = f"ğŸ“Œ **åˆæ­¥è¯†åˆ«çš„åˆåŒç±»å‹**ï¼š{contract_type}\n\n---\n\n"
        for chunk in contract_analyzer.analyze_contract_stream(text, contract_type, file_paths):
            full_response += chunk
            yield full_response

    except Exception as e:
        yield f"âŒ **ç¨‹åºå‘ç”Ÿä¸¥é‡é”™è¯¯**ï¼š\n\n`{str(e)}`"

def reset_system(request: gr.Request=None):
    """Reset the current user's system state and clear their chat history."""
    if request is not None:
        user_id = get_user_id_from_request(request)
        # Reset user state
        user_states[user_id] = SystemState()
        # Clear the saved chat history file
        file_path = get_user_chat_file_path(user_id)
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"å·²åˆ é™¤ç”¨æˆ· {user_id} çš„å†å²è®°å½•æ–‡ä»¶: {file_path}")  # âœ… æ·»åŠ æ—¥å¿—
    else:
        print("è­¦å‘Šï¼šreset_systemè°ƒç”¨æ—¶æœªæä¾›requestå‚æ•°ï¼Œæ— æ³•åˆ é™¤ç‰¹å®šç”¨æˆ·çš„å†å²è®°å½•")
    
    # Fallback to global state reset if user identification fails
    global system_state
    system_state = SystemState()

def chat_legal_knowledge_stream(message, history, request: gr.Request):
    user_id, system_state = get_or_create_user_state(request)
    
    if not system_state.legal_conversation_history or system_state.current_mode != "legal_knowledge":
        system_state.legal_conversation_history = [{'role': Role.SYSTEM, 'content': prompts.LEGAL_CONSULTANT_PROMPT}]
        system_state.current_mode = "legal_knowledge"
    
    system_state.legal_conversation_history.append({'role': Role.USER, 'content': message})
    
    if not history:
        history = []
    
    history.append((message, ""))
    
    try:
        responses = Generation.call(
            model=config.LEGAL_MODEL,
            messages=system_state.legal_conversation_history,
            result_format='message',
            stream=True,
            incremental_output=True
        )
        
        full_response = ""
        
        for response in responses:
            if response.status_code == 200:
                if hasattr(response.output, 'choices') and response.output.choices:
                    delta_content = response.output.choices[0].message.content
                    if delta_content:
                        full_response += delta_content
                        history[-1] = (message, full_response)
                        yield history
                        time.sleep(0.02)
            else:
                error_msg = f"APIé”™è¯¯: {response.code} - {response.message}"
                history[-1] = (message, error_msg)
                yield history
                return
        
        system_state.legal_conversation_history.append({'role': Role.ASSISTANT, 'content': full_response})
        
    except Exception as e:
        error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
        history[-1] = (message, error_msg)
        yield history

def detect_case_type(user_input):
    user_input_lower = user_input.lower().strip()
    
    if user_input_lower in ['1', '2', '3', '4', '5']:
        return user_input_lower
    
    keywords_map = {
        '1': ['åŠ³åŠ¨å…³ç³»', 'ç¡®è®¤å…³ç³»', 'æ˜¯å¦å­˜åœ¨åŠ³åŠ¨å…³ç³»', 'è®¤å®šåŠ³åŠ¨å…³ç³»'],
        '2': ['åŠ³åŠ¨åˆåŒ', 'ç­¾åˆåŒ', 'åˆåŒçº çº·', 'åˆåŒå±¥è¡Œ', 'åˆåŒå˜æ›´', 'åˆåŒè§£é™¤', 'åˆåŒç»ˆæ­¢'],
        '3': ['è¾é€€', 'è¾èŒ', 'ç¦»èŒ', 'é™¤å', 'è¢«å¼€é™¤', 'è¢«ç‚’', 'è§£é›‡', 'è¢«å¼€äº†', 'ä¸ç”¨æ¥', 'å¼€é™¤'],
        '4': ['åŠ ç­', 'å·¥ä½œæ—¶é—´', 'ä¼‘å‡', 'å¹´å‡', 'ç¤¾ä¿', 'ç¤¾ä¼šä¿é™©', 'ç¦åˆ©', 'åŸ¹è®­', 'åŠ³åŠ¨ä¿æŠ¤'],
        '5': ['å·¥èµ„', 'è–ªæ°´', 'æŠ¥é…¬', 'å·¥ä¼¤', 'åŒ»ç–—è´¹', 'è¡¥å¿', 'èµ”å¿é‡‘', 'ç»æµè¡¥å¿']
    }
    
    for case_type, keywords in keywords_map.items():
        for keyword in keywords:
            if keyword in user_input:
                return case_type
    
    return None

def get_case_selection_prompt():
    return """æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“ä¸šåŠ³åŠ¨æ³•å¾‹å¸ˆï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æ³•å¾‹å’¨è¯¢æœåŠ¡ã€‚

åœ¨å¼€å§‹ä¸ºæ‚¨æä¾›ä¸“ä¸šæ³•å¾‹å»ºè®®ä¹‹å‰ï¼Œæˆ‘éœ€è¦äº†è§£æ‚¨é‡åˆ°çš„å…·ä½“æƒ…å†µã€‚åŠ³åŠ¨äº‰è®®æ¡ˆä»¶æ¶‰åŠé¢è¾ƒå¹¿ï¼Œä¸åŒç±»å‹çš„äº‰è®®éœ€è¦é‡‡ç”¨ä¸åŒçš„æ³•å¾‹ç­–ç•¥å’Œè§£å†³æ–¹æ¡ˆã€‚

è¯·æ‚¨è¯¦ç»†æè¿°ä¸€ä¸‹æ‚¨ç›®å‰é¢ä¸´çš„é—®é¢˜ï¼Œæˆ‘ä¼šæ ¹æ®æ‚¨çš„æè¿°å¸®åŠ©æ‚¨ç¡®å®šäº‰è®®ç±»å‹ï¼Œå¹¶ä¸ºæ‚¨åˆ¶å®šæœ€é€‚åˆçš„æ³•å¾‹è§£å†³æ–¹æ¡ˆã€‚æ‚¨å¯ä»¥æ”¾å¿ƒåœ°å‘æˆ‘è¯´æ˜æƒ…å†µï¼Œæˆ‘ä¼šä¸¥æ ¼ä¿æŠ¤æ‚¨çš„éšç§ï¼Œå¹¶ä¸ºæ‚¨æä¾›ä¸“ä¸šã€å®¢è§‚çš„æ³•å¾‹æ„è§ã€‚

è¯·å¼€å§‹æè¿°æ‚¨çš„æƒ…å†µå§ã€‚"""

def detect_conversation_end(lawyer_response):
    if not lawyer_response:
        return True
    
    has_question_mark = 'ï¼Ÿ' in lawyer_response or '?' in lawyer_response
    
    return not has_question_mark

def chat_case_strategy_stream(message, history, request: gr.Request):
    user_id, system_state = get_or_create_user_state(request)
    
    if not system_state.case_conversation_history or system_state.current_mode != "case_strategy":
        system_state.case_conversation_history = [{'role': Role.SYSTEM, 'content': prompts.DEFAULT_LAWYER_SYSTEM_PROMPT}]
        system_state.current_mode = "case_strategy"
        system_state.user_input_round = 0
        system_state.case_type_selected = None
        system_state.current_lawyer_prompt = prompts.DEFAULT_LAWYER_SYSTEM_PROMPT
    
    system_state.user_input_round += 1
    
    if not history:
        history = []
    
    history.append((message, ""))
    
    try:
        if system_state.user_input_round == 1:
            # é¦–å…ˆå°è¯•æ£€æµ‹æ¡ˆä»¶ç±»å‹
            detected_type = detect_case_type(message)
            
            if detected_type:
                # å¦‚æœæ£€æµ‹åˆ°æ¡ˆä»¶ç±»å‹ï¼Œç›´æ¥ç¡®è®¤å¹¶è®¾ç½®
                system_state.case_type_selected = detected_type
                system_state.current_lawyer_prompt = prompt_loader.load_lawyer_prompt(detected_type)
                system_state.case_conversation_history = [{'role': Role.SYSTEM, 'content': system_state.current_lawyer_prompt}]
                
                case_name = config.CASE_TYPES[detected_type]["name"]
                response_msg = f"æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“ä¸šåŠ³åŠ¨æ³•å¾‹å¸ˆï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æ³•å¾‹å’¨è¯¢æœåŠ¡ã€‚æˆ‘äº†è§£æ‚¨çš„æ¡ˆä»¶ç±»å‹æ˜¯ï¼š{case_name}\n\nç°åœ¨è®©æˆ‘ä»¬å¼€å§‹è¯¦ç»†äº†è§£æ‚¨çš„å…·ä½“æƒ…å†µã€‚"
                
                system_state.case_conversation_history.append({'role': Role.USER, 'content': message})
                system_state.case_conversation_history.append({'role': Role.ASSISTANT, 'content': response_msg})
                
                full_response = f"ã€æ¡ˆä»¶ç±»å‹ç¡®è®¤ã€‘\n{response_msg}"
                history[-1] = (message, full_response)
                yield history
                return
            else:
                # å¦‚æœæ£€æµ‹ä¸åˆ°æ¡ˆä»¶ç±»å‹ï¼Œæ˜¾ç¤ºé€‰æ‹©æç¤º
                prompt_response = get_case_selection_prompt()
                system_state.case_conversation_history.append({'role': Role.USER, 'content': message})
                system_state.case_conversation_history.append({'role': Role.ASSISTANT, 'content': prompt_response})
                history[-1] = (message, prompt_response)
                yield history
                return
        
        if system_state.case_type_selected is None:
            detected_type = detect_case_type(message)
            
            if detected_type:
                system_state.case_type_selected = detected_type
                system_state.current_lawyer_prompt = prompt_loader.load_lawyer_prompt(detected_type)
                system_state.case_conversation_history = [{'role': Role.SYSTEM, 'content': system_state.current_lawyer_prompt}]
                
                case_name = config.CASE_TYPES[detected_type]["name"]
                response_msg = f"æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“ä¸šåŠ³åŠ¨æ³•å¾‹å¸ˆï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æ³•å¾‹å’¨è¯¢æœåŠ¡ã€‚æˆ‘äº†è§£æ‚¨çš„æ¡ˆä»¶ç±»å‹æ˜¯ï¼š{case_name}ã€‚\nç°åœ¨è®©æˆ‘ä»¬å¼€å§‹è¯¦ç»†äº†è§£æ‚¨çš„å…·ä½“æƒ…å†µã€‚"
                
                system_state.case_conversation_history.append({'role': Role.USER, 'content': message})
                system_state.case_conversation_history.append({'role': Role.ASSISTANT, 'content': response_msg})
                
                full_response = f"ã€æ¡ˆä»¶ç±»å‹ç¡®è®¤ã€‘\n{response_msg}"
                history[-1] = (message, full_response)
                yield history
                return
            else:
                selection_prompt = "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¯¹ä½ çš„æè¿°è¿›è¡Œæ¡ˆä»¶ç±»å‹åˆ¤æ–­ï¼Œè¯·æ‚¨é‡æ–°æè¿°æ‚¨çš„æƒ…å†µã€‚" + get_case_selection_prompt()
                system_state.case_conversation_history.append({'role': Role.USER, 'content': message})
                system_state.case_conversation_history.append({'role': Role.ASSISTANT, 'content': selection_prompt})
                full_response = f"ã€è¯·é‡æ–°é€‰æ‹©æ¡ˆä»¶ç±»å‹ã€‘\n{selection_prompt}"
                history[-1] = (message, full_response)
                yield history
                return
        
        effective_round = system_state.user_input_round - (2 if system_state.case_type_selected else 1)
        
        if effective_round <= 4:
            polished_message = paralegal.polish_user_input(message)
            system_state.case_conversation_history.append({'role': Role.USER, 'content': polished_message})
            final_message = polished_message
        else:
            system_state.case_conversation_history.append({'role': Role.USER, 'content': message})
            final_message = message
        
        responses = Generation.call(
            model=config.LAWYER_MODEL,
            messages=system_state.case_conversation_history,
            result_format='message',
            stream=True,
            incremental_output=True
        )
        
        full_response = ""
        
        for response in responses:
            if response.status_code == 200:
                if hasattr(response.output, 'choices') and response.output.choices:
                    delta_content = response.output.choices[0].message.content
                    if delta_content:
                        full_response += delta_content
                        display_response = f"ã€å¾‹å¸ˆå›å¤ã€‘\n{full_response}"
                        history[-1] = (message, display_response)
                        yield history
                        time.sleep(0.01)
            else:
                error_msg = f"APIé”™è¯¯: {response.code} - {response.message}"
                history[-1] = (message, error_msg)
                yield history
                return
        
        system_state.case_conversation_history.append({'role': Role.ASSISTANT, 'content': full_response})
        
        should_generate_analysis = detect_conversation_end(full_response)

        if should_generate_analysis and system_state.user_input_round > 3:
            try:
                conversation_content = ""
                for msg in system_state.case_conversation_history:
                    if msg['role'] in ['user', 'assistant']:
                        role_name = "ç”¨æˆ·" if msg['role'] == 'user' else "å¾‹å¸ˆ"
                        content = msg['content']
                        content = re.sub(r'^ã€.*?ã€‘\s*', '', content)
                        conversation_content += f"{role_name}: {content}\n\n"
                
                if conversation_content.strip():
                    analysis_start = "\n\nğŸ¯ **æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆä¸“ä¸šæ¡ˆä¾‹åˆ†ææŠ¥å‘Š...**\n\n"
                    history[-1] = (message, full_response + analysis_start)
                    yield history
                    
                    case_analysis = case_analyzer.generate_case_analysis(conversation_content.strip())
                    
                    if case_analysis and case_analysis != "ç”Ÿæˆåˆ†æå¤±è´¥":
                        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
                        
                        analysis_data = {
                            "timestamp": timestamp,
                            "case_type": config.CASE_TYPES.get(system_state.case_type_selected, {}).get("name", "æœªçŸ¥ç±»å‹"),
                            "conversation": conversation_content,
                            "case_analysis": case_analysis,
                            "analysis_sections": {}
                        }
                        
                        sections = re.split(r'ã€(æ¡ˆæƒ…åˆ†æ|å½“å‰åº”å¯¹æ–¹æ¡ˆ|ç»´æƒä¸èµ”å¿æ–¹æ¡ˆ)ã€‘', case_analysis)
                        for i in range(1, len(sections), 2):
                            if i + 1 < len(sections):
                                section_title = sections[i]
                                section_content = sections[i + 1].strip()
                                analysis_data["analysis_sections"][section_title] = section_content
                        
                        os.makedirs('./case_analysis_results', exist_ok=True)
                        analysis_filename = f"./case_analysis_results/case_analysis_{timestamp}.json"
                        with open(analysis_filename, 'w', encoding='utf-8') as f:
                            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
                        
                        final_content = f"{full_response}\n\nğŸ¯ **ä¸“ä¸šæ¡ˆä¾‹åˆ†ææŠ¥å‘Š**\n\n"
                        
                        paragraphs = case_analysis.split('\n\n')
                        for para in paragraphs:
                            if para.strip():
                                final_content += para + "\n\n"
                                history[-1] = (message, final_content)
                                yield history
                                time.sleep(0.1)

                        summary = f"{final_content}\nâœ… æ¡ˆä¾‹åˆ†æå·²å®Œæˆå¹¶ä¿å­˜ï¼\nğŸ“ æ–‡ä»¶è·¯å¾„ï¼š{analysis_filename}\n\nğŸ’¡ æ‚¨å¯ä»¥ï¼š\n1. ç»§ç»­æé—®è¡¥å……ä¿¡æ¯\n2. å¼€å§‹æ–°çš„å’¨è¯¢\n3. æŸ¥çœ‹ä¿å­˜çš„åˆ†ææŠ¥å‘Š"
                        saved_conversation_file = save_case_conversation_history()
                        if saved_conversation_file:
                            summary += f"\nğŸ“ å¯¹è¯å†å²å·²ä¿å­˜ï¼š{saved_conversation_file}"
                        history[-1] = (message, summary)
                        yield history
                        
                    else:
                        error_msg = f"{full_response}\n\nâŒ æ¡ˆä¾‹åˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                        history[-1] = (message, error_msg)
                        yield history
                        
            except Exception as e:
                error_msg = f"{full_response}\n\nâŒ æ¡ˆä¾‹åˆ†æç”Ÿæˆå‡ºé”™ï¼š{str(e)}"
                history[-1] = (message, error_msg)
                yield history
        
    except Exception as e:
        error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
        history[-1] = (message, error_msg)
        yield history

def save_case_conversation_history(request: gr.Request):
    try:
        user_id, system_state = get_or_create_user_state(request)
        
        if not system_state.case_conversation_history:
            return
        
        sharegpt_data = []
        current_conversation = []
        system_prompt = None
        
        for msg in system_state.case_conversation_history:
            role = msg.get('role', '')
            content = msg.get('content', '')
            
            if role == 'system':
                if current_conversation:
                    sharegpt_data.append({
                        "system_prompt": system_prompt or prompts.DEFAULT_LAWYER_SYSTEM_PROMPT,
                        "conversations": current_conversation
                    })
                    current_conversation = []
                system_prompt = content
            elif role in ['user', 'human']:
                current_conversation.append({"from": "human", "value": content})
            elif role in ['assistant', 'AI']:
                current_conversation.append({"from": "gpt", "value": content})
        
        if current_conversation:
            sharegpt_data.append({
                "system_prompt": system_prompt or prompts.DEFAULT_LAWYER_SYSTEM_PROMPT,
                "conversations": current_conversation
            })
        
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        os.makedirs('./conversation_datasets', exist_ok=True)
        filename = f"./conversation_datasets/case_consultation_{user_id}_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(sharegpt_data, f, ensure_ascii=False, indent=2)
            
        return filename
        
    except Exception as e:
        print(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")
        return None

def detect_user_intent(user_input):
    user_input_lower = user_input.lower().strip()
    
    contract_keywords = [
        'åˆåŒ', 'åŠ³åŠ¨åˆåŒ', 'åˆåŒå®¡æŸ¥', 'åˆåŒåˆ†æ', 'åˆåŒæ£€æŸ¥',
        'åˆåŒåˆè§„', 'åˆåŒé£é™©', 'åˆåŒæ¡æ¬¾', 'åˆåŒæ–‡ä»¶', 'ä¸‰æ–¹',
        'å®¡æŸ¥åˆåŒ', 'åˆ†æåˆåŒ', 'æ£€æŸ¥åˆåŒ', 'åˆåŒé—®é¢˜', 'åè®®',
        'ç«ä¸šé™åˆ¶', 'è¯æ˜'
    ]
    
    legal_knowledge_keywords = [
        'æ³•å¾‹çŸ¥è¯†', 'æ³•å¾‹å’¨è¯¢', 'æ³•å¾‹è§„å®š', 'æ³•å¾‹æ¡æ–‡', 'äº†è§£æ³•å¾‹',
        'ä»€ä¹ˆæ˜¯', 'å¦‚ä½•ç†è§£', 'æ³•å¾‹æ¦‚å¿µ', 'æ³•å¾‹è§£é‡Š', 'æ™®æ³•',
        'æ³•å¾‹å¸¸è¯†', 'æ³•å¾‹é—®é¢˜', 'æ³•å¾‹æ¡æ¬¾', 'æ³•å¾‹ä¾æ®', 'æ³•å¾‹åŸç†',
        'åˆåŒæ³•', 'æ°‘æ³•', 'åˆ‘æ³•', 'è¡Œæ”¿æ³•', 'å©šå§»æ³•', 'ç»§æ‰¿æ³•',
        'çŸ¥è¯†äº§æƒæ³•', 'æ¶ˆè´¹è€…æƒç›Š', 'æˆ¿åœ°äº§æ³•', 'å…¬å¸æ³•', 'æ³•å®š', 'æ³•å¾‹æ³•è§„'
    ]
    
    case_strategy_keywords = [
        'æ¡ˆä»¶å’¨è¯¢', 'æ¡ˆä»¶ç­–ç•¥', 'æˆ‘çš„æ¡ˆå­', 'æˆ‘é‡åˆ°', 'å‘ç”Ÿäº†',
        'å…¬å¸è¾é€€', 'è¢«å¼€é™¤', 'è¢«ç‚’', 'å·¥èµ„æ‹–æ¬ ', 'åŠ ç­è´¹',
        'åŠ³åŠ¨çº çº·', 'åŠ³åŠ¨äº‰è®®', 'å·¥ä¼¤', 'èµ”å¿', 'è¡¥å¿',
        'ä»²è£', 'èµ·è¯‰', 'ç»´æƒ', 'æˆ‘è¯¥æ€ä¹ˆåŠ', 'å¸®æˆ‘åˆ†æ',
        'æˆ‘çš„æƒ…å†µ', 'å…·ä½“æ¡ˆä¾‹', 'å®é™…é—®é¢˜', 'é‡åˆ°é—®é¢˜', 'æˆ‘å·¥ä½œ', 'æˆ‘çš„å·¥ä½œ' 
    ]
    
    if any(keyword in user_input_lower for keyword in contract_keywords):
        return 'contract_review'
    
    if any(keyword in user_input_lower for keyword in case_strategy_keywords):
        return 'case_strategy'
        
    if any(keyword in user_input_lower for keyword in legal_knowledge_keywords):
        return 'legal_knowledge'
        
    return 'unknown'

def unified_chat_with_clear(message, history, request: gr.Request, files=None):
    """åŒ…è£…å‡½æ•°ï¼šæ‰§è¡ŒèŠå¤©åŠŸèƒ½å¹¶æ¸…ç©ºè¾“å…¥æ¡†"""
    for response in unified_chat(message, history, request, files):
        yield response, ""

def unified_chat(message, history, request: gr.Request, files=None):
    # Identify user and load existing history if available
    user_id, system_state = get_or_create_user_state(request)
    
    # å¤„ç†å¯¹continue_promptçš„å“åº”
    if system_state.expecting_continue_response:
        system_state.expecting_continue_response = False  # é‡ç½®æ ‡å¿—
        
        # å®šä¹‰åˆ¤æ–­å…³é”®è¯
        continue_keywords = ["æ˜¯", "yes", "å¥½çš„", "ç»§ç»­"]
        restart_keywords = ["å¦", "no", "ä¸", "é‡æ–°å¼€å§‹"]
        
        message_lower = message.lower().strip()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»§ç»­å…³é”®è¯
        if any(keyword in message_lower for keyword in continue_keywords):
            # ç”¨æˆ·é€‰æ‹©ç»§ç»­ï¼ŒåŠ è½½å†å²å¯¹è¯å’ŒçŠ¶æ€
            if system_state.loaded_history_for_prompt:
                history = system_state.loaded_history_for_prompt
                if system_state.loaded_state_for_prompt:
                    user_states[user_id] = system_state.loaded_state_for_prompt
                    system_state = user_states[user_id]
                # æ¸…ç†ä¸´æ—¶å­˜å‚¨
                system_state.loaded_history_for_prompt = None
                system_state.loaded_state_for_prompt = None
                
                # æ·»åŠ ç¡®è®¤æ¶ˆæ¯
                history.append((message, "âœ… **å·²æ¢å¤æ‚¨çš„å†å²å¯¹è¯**\n\næ‚¨å¯ä»¥ç»§ç»­ä¹‹å‰çš„å¯¹è¯äº†ã€‚"))
                save_user_chat_history(user_id, history, system_state)
                yield history
                return
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡æ–°å¼€å§‹å…³é”®è¯
        elif any(keyword in message_lower for keyword in restart_keywords):
            # ç”¨æˆ·é€‰æ‹©é‡æ–°å¼€å§‹
            reset_system(request)
            new_history = initialize_user_session(request)
            save_user_chat_history(user_id, new_history, system_state)
            yield new_history
            return
        
        else:
            # è¾“å…¥ä¸åŒ…å«æŒ‡å®šå…³é”®è¯ï¼Œé‡æ–°è¯¢é—®
            system_state.expecting_continue_response = True  # é‡æ–°è®¾ç½®æ ‡å¿—
            
            continue_prompt = f"""
ğŸ” **å‘ç°æ‚¨çš„å†å²å¯¹è¯è®°å½•**

æ‚¨ä¸Šæ¬¡å¯¹è¯çš„æœ€åä¸€æ¡æ¶ˆæ¯ï¼š
> {system_state.loaded_history_for_prompt[-1][0] if system_state.loaded_history_for_prompt and system_state.loaded_history_for_prompt[-1][0] else 'ç³»ç»Ÿæ¶ˆæ¯'}

**æ‚¨æƒ³è¦ç»§ç»­ä¸Šæ¬¡çš„å¯¹è¯å—ï¼Ÿ**

âœ… **ç»§ç»­å¯¹è¯** - ä¿ç•™ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œç»§ç»­äº¤æµ
ğŸ”„ **é‡æ–°å¼€å§‹** - æ¸…ç©ºå†å²è®°å½•ï¼Œå¼€å§‹æ–°çš„å¯¹è¯

**è¯·ç›´æ¥å›å¤"ç»§ç»­"æˆ–"é‡æ–°å¼€å§‹"æ¥é€‰æ‹©ã€‚**
            """.strip()
            
            # é‡æ–°æ˜¾ç¤ºæç¤º
            if system_state.loaded_history_for_prompt:
                prompt_history = system_state.loaded_history_for_prompt.copy()
            else:
                prompt_history = []
            prompt_history.append((message, continue_prompt))
            
            yield prompt_history
            return

    loaded = False
    if not history:
        loaded_history, loaded_state = load_user_chat_history(user_id)
        if loaded_history is not None:
            history = loaded_history
            if loaded_state:
                user_states[user_id] = loaded_state
            loaded = True
    
    # Handle file uploads for contract review
    if files and len(files) > 0:
        system_state.current_mode = "contract_review"
        for response in analyze_contracts(files):
            if not history:
                history = []
            if len(history) == 0:
                history.append(("ç”¨æˆ·ä¸Šä¼ äº†åˆåŒæ–‡ä»¶", ""))
            history[-1] = ("ç”¨æˆ·ä¸Šä¼ äº†åˆåŒæ–‡ä»¶", response)
            # Persist after each streaming chunk
            save_user_chat_history(user_id, history, system_state)
            yield history
        system_state.current_mode = "selection"  # Reset after contract review
        save_user_chat_history(user_id, history, system_state)
        return
    
    # If no input message, show initial prompt (or keep loaded history)
    if not message or not message.strip():
        if not history:
            history = []
            history.append(("", get_initial_prompt()))
        # Persist and return current history
        save_user_chat_history(user_id, history, system_state)
        yield history
        return
    
    # Route based on current mode/state
    if system_state.current_mode == "case_strategy":
        for response in chat_case_strategy_stream(message, history, request):
            # Each yielded response is a full history snapshot
            save_user_chat_history(user_id, response, system_state)
            yield response
        if history and "æ¡ˆä¾‹åˆ†æå·²å®Œæˆå¹¶ä¿å­˜ï¼" in history[-1][1]:
            system_state.current_mode = "selection"
        save_user_chat_history(user_id, history, system_state)
    elif system_state.current_mode == "legal_knowledge":
        for response in chat_legal_knowledge_stream(message, history):
            save_user_chat_history(user_id, response, system_state)
            yield response
        system_state.current_mode = "selection"
        save_user_chat_history(user_id, history, system_state)
    elif system_state.current_mode == "contract_review":
        if not history:
            history = []
        history.append((message, "ğŸ“„ **å·²å¤„äºåˆåŒå®¡æŸ¥æ¨¡å¼**è¯·ä¸Šä¼ æ‚¨çš„åŠ³åŠ¨åˆåŒæ–‡ä»¶ï¼ˆæ”¯æŒPDFã€DOCXæˆ–å›¾ç‰‡æ ¼å¼ï¼‰ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ†æåˆåŒåˆè§„æ€§ã€‚"))
        save_user_chat_history(user_id, history, system_state)
        yield history
        system_state.current_mode = "selection"
    else:
        intent = detect_user_intent(message)
        
        if intent == 'contract_review':
            system_state.current_mode = "contract_review"
            if not history:
                history = []
            history.append((message, "ğŸ“„ **åˆåŒå®¡æŸ¥æ¨¡å¼å·²æ¿€æ´»**\n\nè¯·ä¸Šä¼ æ‚¨çš„åŠ³åŠ¨åˆåŒæ–‡ä»¶ï¼ˆæ”¯æŒPDFã€DOCXæˆ–å›¾ç‰‡æ ¼å¼ï¼‰ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ†æåˆåŒåˆè§„æ€§ã€‚\n\nâœ… æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š\nâ€¢ PDFæ ¼å¼åˆåŒ\nâ€¢ Wordæ–‡æ¡£(.docx)\nâ€¢ å›¾ç‰‡æ ¼å¼(JPGã€PNGç­‰)\nâ€¢ æ”¯æŒå¤šå¼ å›¾ç‰‡åŒæ—¶ä¸Šä¼ "))
            save_user_chat_history(user_id, history, system_state)
            yield history
        elif intent == 'legal_knowledge':
            system_state.current_mode = "legal_knowledge"
            for response in chat_legal_knowledge_stream(message, history, request):
                save_user_chat_history(user_id, response, system_state)
                yield response
            system_state.current_mode = "selection"
            save_user_chat_history(user_id, history, system_state)
        elif intent == 'case_strategy':
            system_state.current_mode = "case_strategy"
            for response in chat_case_strategy_stream(message, history, request):
                save_user_chat_history(user_id, response, system_state)
                yield response
            if history and "æ¡ˆä¾‹åˆ†æå·²å®Œæˆå¹¶ä¿å­˜ï¼" in history[-1][1]:
                system_state.current_mode = "selection"
            save_user_chat_history(user_id, history, system_state)
        else:
            if not history:
                history = []
            
            clarification = f"""å¾ˆæŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä»æ‚¨çš„æè¿°ä¸­å‡†ç¡®åˆ¤æ–­æ‚¨éœ€è¦çš„æœåŠ¡ç±»å‹ã€‚

ğŸ¤” **æ‚¨çš„è¾“å…¥**ï¼š"{message}"

ä¸ºäº†æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·æ‚¨æ˜ç¡®å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ï¼š

ğŸ“„ **åˆåŒå®¡æŸ¥** - å¦‚æœæ‚¨è¦ä¸Šä¼ åˆåŒæ–‡ä»¶è¿›è¡Œåˆ†æ
ğŸ“š **æ³•å¾‹çŸ¥è¯†å’¨è¯¢** - å¦‚æœæ‚¨æƒ³äº†è§£æ³•å¾‹æ¡æ–‡æˆ–æ¦‚å¿µ
âš–ï¸ **æ¡ˆä»¶ç­–ç•¥å’¨è¯¢** - å¦‚æœæ‚¨é‡åˆ°å…·ä½“çš„æ³•å¾‹é—®é¢˜éœ€è¦è§£å†³

**è¯·é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ï¼Œæˆ–ç›´æ¥è¯´"åˆåŒå®¡æŸ¥"ã€"æ³•å¾‹å’¨è¯¢"æˆ–"æ¡ˆä»¶å’¨è¯¢"ã€‚**"""
            
            history.append((message, clarification))
            save_user_chat_history(user_id, history, system_state)
            yield history

# def initialize_user_session(request: gr.Request):
#     """Initialize user session when page loads."""
#     user_id, system_state = get_or_create_user_state(request)
    
#     # Try to load existing chat history
#     loaded_history, loaded_state = load_user_chat_history(user_id)
    
#     if loaded_history is not None and len(loaded_history) > 0:
#         # Restore previous state
#         if loaded_state:
#             user_states[user_id] = loaded_state
#         return loaded_history
#     else:
#         # Return initial prompt for new users
#         initial_history = [("", get_initial_prompt())]
#         save_user_chat_history(user_id, initial_history, system_state)
#         return initial_history

def initialize_user_session(request: gr.Request=None):
    """Initialize user session when page loads."""
    user_id, system_state = get_or_create_user_state(request)
    
    # Try to load existing chat history
    loaded_history, loaded_state = load_user_chat_history(user_id)
    
    if loaded_history is not None and len(loaded_history) > 0:
        # Restore previous state
        if loaded_state:
            user_states[user_id] = loaded_state
        return loaded_history
    else:
        # Return initial prompt for new users
        initial_history = [("", get_initial_prompt())]
        save_user_chat_history(user_id, initial_history, system_state)
        return initial_history

def initialize_user_session_with_prompt(request: gr.Request):
    """Initialize user session with prompt to continue previous conversation."""
    user_id, system_state = get_or_create_user_state(request)
    
    # Try to load existing chat history
    loaded_history, loaded_state = load_user_chat_history(user_id)
    
    if loaded_history is not None and len(loaded_history) > 0:
        # Create prompt to ask user if they want to continue
        continue_prompt = f"""
ğŸ” **å‘ç°æ‚¨çš„å†å²å¯¹è¯è®°å½•**

æ‚¨ä¸Šæ¬¡å¯¹è¯çš„æœ€åä¸€æ¡æ¶ˆæ¯ï¼š
> {loaded_history[-1][0] if loaded_history[-1][0] else 'ç³»ç»Ÿæ¶ˆæ¯'}

**æ‚¨æƒ³è¦ç»§ç»­ä¸Šæ¬¡çš„å¯¹è¯å—ï¼Ÿ**

âœ… **ç»§ç»­å¯¹è¯** - ä¿ç•™ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œç»§ç»­äº¤æµ
ğŸ”„ **é‡æ–°å¼€å§‹** - æ¸…ç©ºå†å²è®°å½•ï¼Œå¼€å§‹æ–°çš„å¯¹è¯

**è¯·ç›´æ¥å›å¤"ç»§ç»­"æˆ–"é‡æ–°å¼€å§‹"æ¥é€‰æ‹©ï¼Œæˆ–è¾“å…¥å…¶ä»–å†…å®¹å¼€å§‹æ–°çš„å¯¹è¯ã€‚**
        """.strip()
        
        # è®¾ç½®çŠ¶æ€ï¼Œç­‰å¾…ç”¨æˆ·å“åº”
        system_state.expecting_continue_response = True
        system_state.loaded_history_for_prompt = loaded_history
        system_state.loaded_state_for_prompt = loaded_state
        
        # Add the prompt to history but don't save yet
        prompt_history = loaded_history.copy()
        prompt_history.append(("", continue_prompt))
        
        return prompt_history
    else:
        # No history, proceed with normal initialization
        return initialize_user_session(request)


# Gradio UI
with gr.Blocks(title="AIæ³•å¾‹åŠ©æ‰‹ - ä¸“ä¸šåŠ³åŠ¨æ³•å’¨è¯¢å¹³å°", theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # ğŸ›ï¸ AIæ³•å¾‹åŠ©æ‰‹ - ä¸“ä¸šåŠ³åŠ¨æ³•å’¨è¯¢å¹³å°
        
        **æ¬¢è¿ä½¿ç”¨AIæ³•å¾‹åŠ©æ‰‹ï¼** æˆ‘ä»¬ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„åŠ³åŠ¨æ³•å¾‹æœåŠ¡ï¼ŒåŒ…æ‹¬åˆåŒå®¡æŸ¥ã€æ³•å¾‹çŸ¥è¯†å’¨è¯¢å’Œæ¡ˆä»¶ç­–ç•¥åˆ†æã€‚
        
        ---
        """
    )
    
    with gr.Row():
        with gr.Column(scale=2):
            # Chatbot
            chatbot = gr.Chatbot(
                label="å¯¹è¯è®°å½•",
                height=600,
                value=[]
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    label="è¾“å…¥æ‚¨çš„é—®é¢˜",
                    placeholder="è¯·æè¿°æ‚¨çš„é—®é¢˜æˆ–ä¸Šä¼ åˆåŒæ–‡ä»¶...", 
                    lines=1,
                    scale=4
                )
                with gr.Column(scale=1):
                    submit_btn = gr.Button("å‘é€", variant="primary")
                    clear_btn = gr.Button("ğŸ”„ é‡æ–°å¼€å§‹", variant="secondary")
        
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“ åˆåŒæ–‡ä»¶ä¸Šä¼ ")
            file_input = gr.File(
                label="é€‰æ‹©åˆåŒæ–‡ä»¶ï¼ˆæ”¯æŒPDFã€DOCXã€å›¾ç‰‡ç­‰æ ¼å¼ï¼‰",
                file_count="multiple",
                file_types=[".pdf", ".docx", ".png", ".jpg", ".jpeg", ".bmp", ".tiff", ".webp"]
            )
            upload_btn = gr.Button("å¼€å§‹åˆ†æåˆåŒ", variant="primary")
            
            gr.Markdown(
                """
                ### ğŸ’¡ ä½¿ç”¨æç¤º
                
                **ğŸ“„ åˆåŒå®¡æŸ¥**
                - ä¸Šä¼ åŠ³åŠ¨åˆåŒæ–‡ä»¶
                - æ”¯æŒPDFã€Wordã€å›¾ç‰‡æ ¼å¼
                - è·å¾—ä¸“ä¸šåˆè§„åˆ†æ
                
                **ğŸ“š æ³•å¾‹çŸ¥è¯†å’¨è¯¢**
                - æ³•å¾‹æ¡æ–‡è§£é‡Š
                - æ³•å¾‹æ¦‚å¿µè¯´æ˜
                - å®ç”¨æ³•å¾‹çŸ¥è¯†
                
                **âš–ï¸ æ¡ˆä»¶ç­–ç•¥å’¨è¯¢**  
                - æè¿°å…·ä½“æ¡ˆä»¶æƒ…å†µ
                - è·å¾—ä¸“ä¸šåˆ†æå»ºè®®
                - åˆ¶å®šç»´æƒç­–ç•¥
                """
            )
    
    # Load user's previous history when page loads
    demo.load(
        fn=initialize_user_session_with_prompt,
        inputs=None,
        outputs=chatbot
    )
    
    submit_btn.click(
        fn=unified_chat_with_clear,
        inputs=[msg, chatbot],
        outputs=[chatbot, msg]
    )
    
    msg.submit(
        fn=unified_chat_with_clear,
        inputs=[msg, chatbot],
        outputs=[chatbot, msg]
    )
    
    upload_btn.click(
        fn=unified_chat,
        inputs=[msg, chatbot, file_input],
        outputs=chatbot
    )
    
    def _reset_and_init_history(request: gr.Request):
        reset_system(request)
        return initialize_user_session(request)
    
    clear_btn.click(
        fn=_reset_and_init_history,
        inputs=None,
        outputs=chatbot
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7861, show_error=True)